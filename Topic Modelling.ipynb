{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "sonnetsCorpus = PlaintextCorpusReader(\"sonnets\", \".*\\.txt\")\n",
    "print(len(sonnetsCorpus.fileids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def get_lists_of_words(corpus, **kwargs):\n",
    "    documents = []\n",
    "    for fileid in corpus.fileids():\n",
    "        words = [token.lower() for token in corpus.words(fileid) if token[0].isalpha()]\n",
    "        \n",
    "        if \"minLen\" in kwargs and kwargs[\"minLen\"]:\n",
    "            words = [word for word in words if len(word) >= kwargs[\"minLen\"]]\n",
    "            \n",
    "        if \"stopwords\" in kwargs and kwargs[\"stopwords\"]:\n",
    "            words = [word for word in words if word not in kwargs[\"stopwords\"]]\n",
    "        \n",
    "        if \"pos\" in kwargs and kwargs[\"pos\"]:\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            words = [word for word, pos in tagged if pos in kwargs[\"pos\"]]\n",
    "        \n",
    "        documents.append(words)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnetsStopwords = nltk.corpus.stopwords.words('english')\n",
    "sonnetsStopwords += [\"thee\", \"thou\", \"thy\"]\n",
    "sonnetsWords = get_lists_of_words(sonnetsCorpus, stopwords=sonnetsStopwords, minLen=3)\n",
    "\n",
    "for i in range(0,154):\n",
    "    print(\"document\", str(i), sonnetsWords[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lda_from_list_of_words(lists_of_words, **kwargs):\n",
    "    # create a dictionary mapping terms to integer IDs and frequency counts\n",
    "    dictionary = corpora.Dictionary(lists_of_words)\n",
    "\n",
    "#    dictionary.save_as_text(\"fname.txt\") \n",
    "\n",
    "    # convert each document (i.e., each word list in the lists_of_words)\n",
    "    # into a bag-of-words format\n",
    "    corpus = [dictionary.doc2bow(text) for text in lists_of_words]\n",
    "    \n",
    "    # Model the signficance of the words by document\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    # set the dictionary, then do the LDA topic modelling, returning the model to the fxn call\n",
    "    kwargs[\"id2word\"] = dictionary\n",
    "    return models.LdaModel(corpus_tfidf, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(sonnetsWords)\n",
    "test2bow = dictionary.doc2bow(sonnetsWords[0])\n",
    "print(test2bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnetsLda = get_lda_from_list_of_words(sonnetsWords, num_topics=10, passes=20)\n",
    "print(sonnetsLda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_terms(lda, num_terms=10):\n",
    "    for i in range(0, lda.num_topics):\n",
    "        terms = [term for term, val in lda.show_topic(i, num_terms)]\n",
    "        print(\"Top 10 terms for topic #\", str(i), \": \", \", \".join(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnetsLda.print_topic(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sonnetsLda.show_topics(num_topics=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_terms(sonnetsLda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "G = nx.Graph()\n",
    "G.add_edge(\"A\", \"X\")\n",
    "G.add_edge(\"A\", \"Y\")\n",
    "G.add_edge(\"B\", \"X\")\n",
    "G.add_edge(\"C\", \"Y\")\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx_labels(G, pos, font_color='r') # font colour is \"r\" for red\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.1) # set the line alpha transparency to .1\n",
    "plt.axis('off') # don't show the axes for this plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def graph_terms_to_topics(lda, num_terms=10):\n",
    "    \n",
    "    # create a new graph and size it\n",
    "    G = nx.Graph()\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # generate the edges\n",
    "    for i in range(0, lda.num_topics):\n",
    "        topicLabel = \"topic \"+str(i)\n",
    "        terms = [val for val, term in lda.show_topic(i, num_terms)]\n",
    "        for term in terms:\n",
    "            G.add_edge(topicLabel, term)\n",
    "    \n",
    "    pos = nx.spring_layout(G) # positions for all nodes\n",
    "\n",
    "    # we'll plot topic labels and terms labels separately to have different colours\n",
    "  \n",
    "    g = G.subgraph([topic for topic, _ in pos.items() if \"topic \" in str(topic)])\n",
    "    nx.draw_networkx_labels(g, pos,  font_color='r')\n",
    "    g = G.subgraph([term for term, _ in pos.items() if \"topic \" not in str(term)])\n",
    "    nx.draw_networkx_labels(g, pos)\n",
    "    \n",
    "    # plot edges\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=G.edges(), alpha=0.1)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_terms_to_topics(sonnetsLda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
